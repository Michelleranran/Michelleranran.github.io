# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/publication/cvpr23.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**GFPose: Learning 3D Human Pose Prior with Gradient Fields**

Hai Ci, Mingdong Wu, Wentao Zhu, Xiaoxuan Ma, Hao Dong, **Fangwei Zhong&#x2709;**, Yizhou Wang

**CVPR 2023**,
[Project](https://sites.google.com/view/gfpose/) <strong><span class='show_paper_citations' data='ejDz1bYAAAAJ:8k81kl-MbHgC'></span></strong>, 
[Paper](https://arxiv.org/abs/2212.08641)
[![code](https://img.shields.io/github/stars/Embracing/GFPose?style=social&label=Code+Stars)](https://github.com/Embracing/GFPose) 
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/gfpose-learning-3d-human-pose-prior-with/multi-hypotheses-3d-human-pose-estimation-on)](https://paperswithcode.com/sota/multi-hypotheses-3d-human-pose-estimation-on?p=gfpose-learning-3d-human-pose-prior-with)
- a versatile framework to model plausible 3D human poses for various applications.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2023</div><img src='images/publication/iclr23.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Proactive Multi-Camera Collaboration for 3D Human Pose Estimation**

Hai Ci*, Mickel Liu*, Xuehai Pan*, **Fangwei Zhong&#x2709;**, Yizhou Wang

**ICLR 2023**, 
[Project](https://sites.google.com/view/active3dpose) <strong><span class='show_paper_citations' data='ejDz1bYAAAAJ:MXK_kJrjxJIC'></span></strong>,
[Paper](https://openreview.net/pdf?id=CPIy9TWFYBG)
- We propose a novel MARL framework to solve proactive multi-camrea collaborations for 3D HPE in human crowds.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/publication/aaai23.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking]()

**Fangwei Zhong***,  Xiao Bi*,  Yudi Zhang,  Wei Zhang, Yizhou Wang

**AAAI 2023** <span style="color:red">(Oral)</span><strong><span class='show_paper_citations' data=''></span></strong>, 
[Project](https://sites.google.com/view/aot-rspt)
- we propose a framework called RSPT to form a structure-aware motion representation by Reconstructing Surroundings and Predicting the target Trajectory.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022</div><img src='images/publication/neurips22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**TarGF: Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification**

Mingdong Wu*, **Fangwei Zhong***, Yulong Xia, Hao Dong

[Project](https://sites.google.com/view/targf) <strong><span class='show_paper_citations' data='ejDz1bYAAAAJ:0EnyYjriUFMC'></span></strong>,
[Paper](https://arxiv.org/pdf/2209.00853.pdf),
[Code](https://github.com/AaronAnima/TarGF) 
- We develop a framework based on a target gradient field trained by score-matching to tackle object rearrangement without explicit goal specification.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS D&B 2022</div><img src='images/publication/mate.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**MATE: Benchmarking Multi-Agent Reinforcement Learning in Distributed Target Coverage Control**

Xuehai Pan*, Mickel Liu*, **Fangwei Zhong&#x2709;**, Yaodong Yang&#x2709;, Song-Chun Zhu, Yizhou Wang

[Project](https://github.com/UnrealTracking/mate) <strong><span class='show_paper_citations' data='ejDz1bYAAAAJ:5nxA0vEk-isC'></span></strong>, 
[Paper](https://openreview.net/pdf?id=SyoUVEyzJbE),
[![code](https://img.shields.io/github/stars/UnrealTracking/mate?style=social&label=Code+Stars)](https://github.com/UnrealTracking/mate) 
- A gamification of the multi-camera multi-target target coverage problem, and an all-in-one multi-agent reinforcement learning benchmark
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2022</div><img src='images/publication/icml22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Disentangling Disease-related Representation from Obscure for Disease Prediction**

Chu-Ran Wang, Fei Gao, **Fangwei Zhong&#x2709;**, Fangwei Zhong, Yizhou Yu, Yizhou Wang

[Paper](https://proceedings.mlr.press/v162/wang22f/wang22f.pdf)
- A disentanglement learning strategy under the guidance of alpha blending generation in an encoder-decoder framework (DAB-Net).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2022</div><img src='images/publication/iclr22.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind**

Yuanfei Wang*, **Fangwei Zhong***, Jing Xu, Yizhou Wang

[Paper](hhttps://arxiv.org/pdf/2111.09189.pdf), [![code](https://img.shields.io/github/stars/UnrealTracking/mate?style=social&label=Code+Stars)](https://github.com/UnrealTracking/ToM2C) 
- A Target-oriented Multi-agent Communication and Cooperation mechanism using Theory of Mind. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2021</div><img src='images/publication/icml21.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Towards Distraction-Robust Active Visual Tracking**

**Fangwei Zhong**, Peng Sun, Wenhan Luo, Tingyun Yan, Yizhou Wang

[Project](https://sites.google.com/view/distraction-robust-avt),
[Paper](http://proceedings.mlr.press/v139/zhong21b/zhong21b.pdf), 
[Code ![code](https://img.shields.io/github/stars/zfw1226/active_tracking_rl?style=social&label=Code+Stars)](https://github.com/zfw1226/active_tracking_rl/tree/distractor),
[Environment ![code](https://img.shields.io/github/stars/zfw1226/gym-unrealcv?style=social&label=Code+Stars)](https://github.com/zfw1226/gym-unrealcv)
- A mixed cooperative-competitive multi-agent game: a target and multiple distractors form a collaborative team to play against a tracker. 
- A bunch of practical methods: a reward function for distractors, a cross-modal teacher-student learning strategy, and a recurrent attention module for the tracker.
</div>
</div>
